%!TEX root=./report.tex

\section{INTRODUCTION}
Research in robotics and computer vision has long considered the use of 3-D point clouds as a rich source of information about the world.
Throughout the history of research, the recognition methods and features considered have shared ideas--from early work on retrieving 3-D shape models to integrating 2-D and 3-D percepts to human pose estimation.
But the sheer diversity of applications has made it hard to see the common patterns, and nearly impossible to meaningfully compare between different choices made in the processing pipeline.

We hope to foster easier sharing of ideas and methods through a common evaluation framework for 3-D perception tasks.
In this paper, we present an open-source framework for comparing different 3-D features in the model matching evaluation regime.
We explain the motivations behind our system and describe its modular architecture, with the aim of encouraging a community of users and contributors.
The PR-2 \note{citation?} has facilitated rapid progress in personal robotics research due to standardization and abstraction of the hardware interface.
Our system, Proctor, aims for the same kind of impact in 3-D features, and classification and pose estimation methods research.

\section{RELATED WORK}



\subsection{Features}
try to make clear that people do wildly different things for 3d recognition, and cant really compare

\subsection{Datasets}
should datasets go here or in separate section?